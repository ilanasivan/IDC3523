{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLPEX2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 2\n",
        "\n",
        "This assignment is about training and evaluating a POS tagger with some real data. The dataset is available through the Universal Dependencies (https://universaldependencies.org/) (UD) project. To get to know the project, please visit https://universaldependencies.org/introduction.html)\n"
      ],
      "metadata": {
        "id": "puSMwH-ftRgn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUsARMHxr8U3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92335362-c9fa-4650-f826-6b7004ade531"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: conllutils in /usr/local/lib/python3.7/dist-packages (1.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from conllutils) (1.21.6)\n",
            "Requirement already satisfied: conll-df in /usr/local/lib/python3.7/dist-packages (0.0.4)\n",
            "Requirement already satisfied: pandas>=0.19.2 in /usr/local/lib/python3.7/dist-packages (from conll-df) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19.2->conll-df) (2022.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19.2->conll-df) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19.2->conll-df) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.19.2->conll-df) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import operator\n",
        "import nltk\n",
        "from scipy import stats \n",
        "from collections import defaultdict\n",
        "\n",
        "!pip install conllutils\n",
        "import conllutils\n",
        "\n",
        "!pip install conll-df\n",
        "from conll_df import conll_df # https://github.com/interrogator/conll-df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 1** (getting the data)\n",
        "\n",
        "You can download the dataset files directly from the UD website, but it will let you only download all the languages in one compressed file. In this assignment you will be working with th GUM dataset, which you can download directly from:\n",
        "https://github.com/UniversalDependencies/UD_English-GUM.\n",
        "Please download it to your colab machine."
      ],
      "metadata": {
        "id": "bhBsuoGDtNZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/UniversalDependencies/UD_English-GUM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIco2VHesIe8",
        "outputId": "6cb9d156-67b8-46ab-f654-ba70aedf56ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'UD_English-GUM' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the (train/dev/test) files:\n",
        "\n",
        "UD_English-GUM/en_gum-ud-train.conllu\n",
        "\n",
        "UD_English-GUM/en_gum-ud-dev.conllu\n",
        "\n",
        "UD_English-GUM/en_gum-ud-test.conllu\n",
        "\n",
        "They are all formatted in the conllu format. You may read about it [here](https://universaldependencies.org/format.html). There is a utility library **conllutils**, which can help you read the data into the memory. It has already been installed and imported above.\n",
        "\n",
        "You should write a code that reads the three datasets into memory. You may choose the data structure by yourself. As you can see, every word is represented by a line, with columns representing specific features. We are only interested in the first and fourth columns, corresponding to the word and its POS tag."
      ],
      "metadata": {
        "id": "AnK_iWc_tJLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "directory = 'UD_English-GUM'\n",
        "word = 'w'\n",
        "position = 'x'\n",
        "\n",
        "train = f'{directory}/en_gum-ud-train.conllu'\n",
        "test = f'{directory}/en_gum-ud-test.conllu'\n",
        "dev = f'{directory}/en_gum-ud-dev.conllu'\n",
        "\n",
        "train_df = conll_df(train, file_index=False)[[word, position]]\n",
        "test_df = conll_df(test, file_index=False)[[word, position]]\n",
        "dev_df = conll_df(dev, file_index=False)[[word, position]]"
      ],
      "metadata": {
        "id": "dFHPbtWPsMZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 2**\n",
        "\n",
        "Write a class **simple_tagger**, with methods *train* and *evaluate*. The method *train* receives the data as a list of sentences, and use it for training the tagger. In this case, it should learn a simple dictionary that maps words to tags, defined as the most frequent tag for every word (in case there is more than one most frequent tag, you may select one of them randomly). The dictionary should be stored as a class member for evaluation.\n",
        "\n",
        "The method *evaluate* receives the data as a list of sentences, and use it to evaluate the tagger performance. Specifically, you should calculate the word and sentence level accuracy.\n",
        "The evaluation process is simply going word by word, querying the dictionary (created by the train method) for each word’s tag and compare it to the true tag of that word. The word-level accuracy is the number of successes divided by the number of words. For OOV (out of vocabulary, or unknown) words, the tagger should assign the most frequent tag in the entire training set (i.e., the mode). The function should return the two numbers: word level accuracy and sentence level accuracy.\n"
      ],
      "metadata": {
        "id": "1oGi0O88tByu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper functions\n",
        "def create_word_tag_dict(data: pd.DataFrame):\n",
        "  word_to_tag_dict = defaultdict(list)\n",
        "\n",
        "  for word, tag in data.itertuples(index=False):\n",
        "    word_to_tag_dict[word].append(tag)\n",
        "  return {key: stats.mode(val).mode[0] for key, val in word_to_tag_dict.items()}\n",
        "\n",
        "def get_most_frequent_tag(data: pd.DataFrame, column=position):\n",
        "  return data[column].value_counts().idxmax()"
      ],
      "metadata": {
        "id": "_YLgU8Q5sQMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class simple_tagger:\n",
        "  def __init__(self):\n",
        "    self.dictionary = {}\n",
        "    self.tag = ''\n",
        "\n",
        "  def train(self, data):\n",
        "    self.word_to_modal_tag_dict = create_word_tag_dict(data)\n",
        "    self.most_frequent_tag = get_most_frequent_tag(data)\n",
        "  \n",
        "  def evaluate(self, data):\n",
        "    correct_word_counter = 0\n",
        "    correct_sentence_counter = 0\n",
        "    num_words = len(data)\n",
        "    \n",
        "    df_grouped_by_sentence = data.groupby('s')\n",
        "    num_sentences = df_grouped_by_sentence.ngroups\n",
        "\n",
        "    for sentence_num, sentence_df in df_grouped_by_sentence:\n",
        "      sentence_correct = True\n",
        "      for _, (word, true_tag) in sentence_df.iterrows():\n",
        "        predicted_tag = self.word_to_modal_tag_dict.get(word, self.most_frequent_tag)\n",
        "        if predicted_tag == true_tag:\n",
        "          correct_word_counter += 1\n",
        "        else:\n",
        "          sentence_correct = False\n",
        "      if sentence_correct: \n",
        "        correct_sentence_counter += 1\n",
        "\n",
        "    w = round(correct_word_counter / num_words * 100, 4)\n",
        "    s = round(correct_sentence_counter / num_sentences * 100, 4)\n",
        "    \n",
        "    return w, s"
      ],
      "metadata": {
        "id": "YcRWW6CpsT0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tagger = simple_tagger()\n",
        "tagger.train(train_df)\n",
        "\n",
        "word_train, sentence_train = tagger.evaluate(train_df)\n",
        "word_test, sentence_test = tagger.evaluate(test_df)\n",
        "word_dev, sentence_dev = tagger.evaluate(dev_df)"
      ],
      "metadata": {
        "id": "n6Wu6sRNsXNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame([\n",
        "              [word_train, sentence_train],\n",
        "              [word_test, sentence_test],\n",
        "              [word_dev, sentence_dev]\n",
        "], columns = ['Word Accuracy (%)', 'Sentence Accuracy (%)'], index = [\"Train\", \"Test\", \"Dev\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "3I0tQ48hqfyg",
        "outputId": "53364094-7ddd-4744-ed81-4146d0531345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Word Accuracy (%)  Sentence Accuracy (%)\n",
              "Train            93.9776                40.6111\n",
              "Test             84.5284                19.1011\n",
              "Dev              85.5558                15.8163"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ec8008db-cea8-4f65-be3d-3174fc7cfb45\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word Accuracy (%)</th>\n",
              "      <th>Sentence Accuracy (%)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Train</th>\n",
              "      <td>93.9776</td>\n",
              "      <td>40.6111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Test</th>\n",
              "      <td>84.5284</td>\n",
              "      <td>19.1011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dev</th>\n",
              "      <td>85.5558</td>\n",
              "      <td>15.8163</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec8008db-cea8-4f65-be3d-3174fc7cfb45')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ec8008db-cea8-4f65-be3d-3174fc7cfb45 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ec8008db-cea8-4f65-be3d-3174fc7cfb45');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 3**\n",
        "\n",
        "Similar to part 2, write the class hmm_tagger, which implements HMM tagging. The method *train* should build the matrices A, B and Pi, from the data as discussed in class. The method *evaluate* should find the best tag sequence for every input sentence using the Viterbi decoding algorithm, and then calculate the word and sentence level accuracy using the gold-standard tags. You should implement the Viterbi algorithm in the next block and call it from your class.\n",
        "\n",
        "Additional guidance:\n",
        "1. The matrix B represents the emissions probabilities. Since B is a matrix, you should build a dictionary that maps every unique word in the corpus to a serial numeric id (starting with 0). This way columns in B represents word ids.\n",
        "2. During the evaluation, you should first convert each word into it’s index and then create the observation array to be given to Viterbi, as a list of ids. OOV words should be assigned with a random tag. To make sure Viterbi works appropriately, you can simply break the sentence into multiple segments every time you see an OOV word, and decode every segment individually using Viterbi."
      ],
      "metadata": {
        "id": "7HXL96iKs78R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# helper functions\n",
        "def accuracy(data, tags):\n",
        "  correct_word_counter = word_count = correct_sentence_counter = 0\n",
        "\n",
        "  for (sentence, words_tags) in zip(data, tags):\n",
        "    word_count += len(words_tags)\n",
        "    sentence_success = True \n",
        "    for word in range(len(sentence)):\n",
        "      tag = words_tags[word][1] if isinstance(words_tags[word], tuple) else words_tags[word]\n",
        "      if tag == sentence[word][1]:\n",
        "        correct_word_counter += 1\n",
        "      else:\n",
        "        sentence_success = False\n",
        "    if sentence_success:\n",
        "      correct_sentence_counter += 1\n",
        "  \n",
        "  w = round((correct_word_counter / word_count) * 100, 4)\n",
        "  s = round((correct_sentence_counter / len(tags)) * 100, 4)\n",
        "  return w,s"
      ],
      "metadata": {
        "id": "nlZgk4_N7bCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class hmm_tagger:\n",
        "  A = B = Pi = None\n",
        "  words_ids = {}\n",
        "  pos_ids = {}\n",
        "\n",
        "  def create_matrices(self, data):\n",
        "    word_count = 0\n",
        "    tag_count = 0\n",
        "    for sentence in data:\n",
        "      for (word, tag) in sentence:\n",
        "        if self.words_ids.get(word, -1) == -1:\n",
        "          self.words_ids[word] = word_count\n",
        "          word_count += 1\n",
        "        if self.pos_ids.get(tag, -1) == -1:\n",
        "          self.pos_ids[tag] = tag_count\n",
        "          tag_count += 1\n",
        "    self.A = np.zeros((tag_count, tag_count))\n",
        "    self.B = np.zeros((tag_count, word_count))\n",
        "    self.Pi = np.zeros(tag_count)\n",
        "    \n",
        "  def train(self, data):\n",
        "    self.create_matrices(data)\n",
        "\n",
        "    for sentence in data:\n",
        "      (word, tag) = sentence[0]\n",
        "      self.Pi[self.pos_ids[tag]] += 1\n",
        "      self.B[self.pos_ids[tag]][self.words_ids[word]] += 1\n",
        "      for i,j in zip(range(len(sentence)), range(1, len(sentence))):\n",
        "        tag_i = sentence[i][1]\n",
        "        (word_j, tag_j) = sentence[j]\n",
        "        self.A[self.pos_ids[tag_i]][self.pos_ids[tag_j]] += 1\n",
        "        self.B[self.pos_ids[tag_j]][self.words_ids[word_j]] += 1\n",
        "    \n",
        "    for i in range(self.Pi.shape[0]):\n",
        "      self.A[i] /= (self.A[i].sum() or 1)\n",
        "      self.B[i] /= (self.B[i].sum() or 1)\n",
        "    self.Pi /= len(data)\n",
        "\n",
        "  def evaluate(self, data):\n",
        "    pos_tags = sorted(self.pos_ids, key=self.pos_ids.get)\n",
        "    tags = []\n",
        "\n",
        "    for sentence in data:\n",
        "      observations = [self.words_ids.get(word, -1) for (word, tag) in sentence]\n",
        "      sentence_tags = []\n",
        "      last = 0\n",
        "      for obs in range(len(observations)):\n",
        "        if observations[obs] == -1:\n",
        "          if last != obs:\n",
        "            sentence_tags += viterbi(observations[last:obs], self.A, self.B, self.Pi)\n",
        "          sentence_tags.append(random.choice(list(self.pos_ids.values())))\n",
        "          last = obs+1\n",
        "      if last < len(observations):\n",
        "        sentence_tags += viterbi(observations[last:], self.A, self.B, self.Pi)\n",
        "      tags.append([pos_tags[tag] for tag in sentence_tags])\n",
        "\n",
        "    return accuracy(data, tags)"
      ],
      "metadata": {
        "id": "e9yMCENEsfOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Viterbi\n",
        "def viterbi (observations, A, B, Pi):\n",
        "  N = A.shape[0]\n",
        "  T = len(observations)\n",
        "  delta = np.zeros((N, T))\n",
        "  psi = np.zeros((N, T))\n",
        "  best_sequence = np.zeros(T, dtype=int)\n",
        "  for n in range(N):\n",
        "    delta[n][0] = B[n][observations[0]] * Pi[n]\n",
        "    psi[n][0] = 0\n",
        "  for t in range(1,T):\n",
        "    for n in range(N):\n",
        "      (max_val, j) = max([(delta[j][t-1] * A[j][n], j) for j in range(N)], key= lambda p: p[0])\n",
        "      delta[n][t] = B[n][observations[t]] * max_val\n",
        "      psi[n][t] = j\n",
        "\n",
        "  best_sequence[T-1] = max([(delta[j][T-1], j) for j in range(N)], key= lambda p: p[0])[1]\n",
        "  for t in reversed(range(T-1)):\n",
        "    best_sequence[t] = psi[best_sequence[t+1]][t+1]\n",
        "\n",
        "  return list(best_sequence)"
      ],
      "metadata": {
        "id": "FOGp3DMTsixF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 4**\n",
        "\n",
        "Compare the results obtained from both taggers and a MEMM tagger, implemented by NLTK (a known NLP library), over both, the dev and test datasets. To train the NLTK MEMM tagger you should execute the following lines (it may take some time to train...):"
      ],
      "metadata": {
        "id": "_nqL3_VCs1bF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tag import tnt \n",
        "\n",
        "%cd /content/UD_English-GUM/\n",
        "!git checkout 2c8b062269f2d2d3d62405c82d8c25cf24f705dd\n",
        "%cd ..\n",
        "def read_data(file_name):\n",
        "  data = []\n",
        "  file_path = f'UD_English-GUM/en_gum-ud-{file_name}.conllu'\n",
        "  for sentence in conllutils.read_conllu(file_path):\n",
        "    data.append([(token['form'], token['upos']) for token in sentence.tokens()])\n",
        "  return data\n",
        "\n",
        "train_data = read_data('train')\n",
        "test_data = read_data('test')\n",
        "dev_data = read_data('dev')\n",
        "\n",
        "tnt_pos_tagger = tnt.TnT()\n",
        "tnt_pos_tagger.train(train_data)\n",
        "print(tnt_pos_tagger.evaluate(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8vqYrxNsmSc",
        "outputId": "ba35d7e9-414b-4cb3-d889-0528ca9fafed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UD_English-GUM\n",
            "HEAD is now at 2c8b062 Updated statistics.\n",
            "/content\n",
            "0.802335803089288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print both, word level and sentence level accuracy for all the three taggers in a table."
      ],
      "metadata": {
        "id": "YBT1E3LbsxNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from nltk.tag.util import untag\n",
        "\n",
        "tnt_dev_tagged_sents = tnt_pos_tagger.tag_sents(untag(sent) for sent in dev_data)\n",
        "tnt_test_tagged_sents = tnt_pos_tagger.tag_sents(untag(sent) for sent in test_data)\n",
        "tnt_dev_results = accuracy(dev_data, tnt_dev_tagged_sents)\n",
        "tnt_test_results = accuracy(test_data, tnt_test_tagged_sents)\n",
        "\n",
        "simple_pos_tagger = simple_tagger()\n",
        "simple_pos_tagger.train(train_df)\n",
        "simple_dev_results = simple_pos_tagger.evaluate(dev_df)\n",
        "simple_test_results =  simple_pos_tagger.evaluate(test_df)\n",
        "\n",
        "train_data = read_data('train')\n",
        "hmm_pos_tagger = hmm_tagger()\n",
        "hmm_pos_tagger.train(train_data)\n",
        "hmm_dev_results = hmm_pos_tagger.evaluate(dev_data)\n",
        "hmm_test_results =  hmm_pos_tagger.evaluate(test_data)"
      ],
      "metadata": {
        "id": "Ox1zo64Tsrmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame([\n",
        "                [simple_dev_results[0], simple_dev_results[1], simple_test_results[0], simple_test_results[1]], \n",
        "                [hmm_dev_results[0], hmm_dev_results[1], hmm_test_results[0], hmm_test_results[1]],\n",
        "                [tnt_dev_results[0], tnt_dev_results[1], tnt_test_results[0], tnt_test_results[1]],\n",
        "], columns=['Word Accuracy (Dev)', 'Sentence Accuracy (Dev)', 'Word Accuracy (Test)', 'Sentence Accuracy (Test)'], index=['Simple', 'HMM', 'MEMM'])"
      ],
      "metadata": {
        "id": "6QpNFtrCpj44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "1f86a927-6d53-464b-f311-193e05d2d6f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Word Accuracy (Dev)  Sentence Accuracy (Dev)  Word Accuracy (Test)  \\\n",
              "Simple              85.5558                  15.8163               84.5284   \n",
              "HMM                 83.2222                  13.1378               80.9243   \n",
              "MEMM                82.7863                  12.7551               80.2336   \n",
              "\n",
              "        Sentence Accuracy (Test)  \n",
              "Simple                   19.1011  \n",
              "HMM                      12.6966  \n",
              "MEMM                     12.3596  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8bc8e9b8-e331-42d3-9704-98a8f92745ae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word Accuracy (Dev)</th>\n",
              "      <th>Sentence Accuracy (Dev)</th>\n",
              "      <th>Word Accuracy (Test)</th>\n",
              "      <th>Sentence Accuracy (Test)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Simple</th>\n",
              "      <td>85.5558</td>\n",
              "      <td>15.8163</td>\n",
              "      <td>84.5284</td>\n",
              "      <td>19.1011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HMM</th>\n",
              "      <td>83.2222</td>\n",
              "      <td>13.1378</td>\n",
              "      <td>80.9243</td>\n",
              "      <td>12.6966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MEMM</th>\n",
              "      <td>82.7863</td>\n",
              "      <td>12.7551</td>\n",
              "      <td>80.2336</td>\n",
              "      <td>12.3596</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8bc8e9b8-e331-42d3-9704-98a8f92745ae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8bc8e9b8-e331-42d3-9704-98a8f92745ae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8bc8e9b8-e331-42d3-9704-98a8f92745ae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}